{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\UNI\\Thesis\\NeuralNotes\\agent\\attribute.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/UNI/Thesis/NeuralNotes/agent/attribute.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mpickle\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/UNI/Thesis/NeuralNotes/agent/attribute.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/UNI/Thesis/NeuralNotes/agent/attribute.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m pickle_load\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/UNI/Thesis/NeuralNotes/agent/attribute.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m Counter\n",
      "File \u001b[1;32md:\\UNI\\Thesis\\NeuralNotes\\agent\\utils.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspatial\u001b[39;00m \u001b[39mimport\u001b[39;00m distance\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmidi2audio\u001b[39;00m \u001b[39mimport\u001b[39;00m FluidSynth\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mchord_recognition\u001b[39;00m \u001b[39mimport\u001b[39;00m MIDIChord\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmiditoolkit\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmidi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparser\u001b[39;00m \u001b[39mimport\u001b[39;00m MidiFile\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmiditoolkit\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmidi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontainers\u001b[39;00m \u001b[39mimport\u001b[39;00m Note, TempoChange, Marker, Instrument\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import os, pickle\n",
    "import numpy as np\n",
    "\n",
    "from utils import pickle_load\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './remi_dataset'\n",
    "polyph_out_dir = './remi_dataset/attr_cls/polyph'\n",
    "rhythm_out_dir = './remi_dataset/attr_cls/rhythm'\n",
    "\n",
    "rhym_intensity_bounds = [0.2, 0.25, 0.32, 0.38, 0.44, 0.5, 0.63]\n",
    "polyphonicity_bounds = [2.63, 3.06, 3.50, 4.00, 4.63, 5.44, 6.44]\n",
    "\n",
    "def compute_polyphonicity(events, n_bars):\n",
    "  poly_record = np.zeros( (n_bars * 16,) )\n",
    "\n",
    "  cur_bar, cur_pos = -1, -1\n",
    "  for ev in events:\n",
    "    if ev['name'] == 'Bar':\n",
    "      cur_bar += 1\n",
    "    elif ev['name'] == 'Beat':\n",
    "      cur_pos = int(ev['value'])\n",
    "    elif ev['name'] == 'Note_Duration':\n",
    "      duration = int(ev['value']) // 120\n",
    "      st = cur_bar * 16 + cur_pos\n",
    "      poly_record[st:st + duration] += 1\n",
    "  \n",
    "  return poly_record\n",
    "\n",
    "def get_onsets_timing(events, n_bars):\n",
    "  onset_record = np.zeros( (n_bars * 16,) )\n",
    "\n",
    "  cur_bar, cur_pos = -1, -1\n",
    "  for ev in events:\n",
    "    if ev['name'] == 'Bar':\n",
    "      cur_bar += 1\n",
    "    elif ev['name'] == 'Beat':\n",
    "      cur_pos = int(ev['value'])\n",
    "    elif ev['name'] == 'Note_Pitch':\n",
    "      rec_idx = cur_bar * 16 + cur_pos\n",
    "      onset_record[ rec_idx ] = 1\n",
    "\n",
    "  return onset_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pieces = [p for p in sorted(os.listdir(data_dir)) if '.pkl' in p]\n",
    "print(pieces)\n",
    "all_r_cls = []\n",
    "all_p_cls = []\n",
    "\n",
    "if not os.path.exists(polyph_out_dir):\n",
    "    os.makedirs(polyph_out_dir)\n",
    "if not os.path.exists(rhythm_out_dir):\n",
    "    os.makedirs(rhythm_out_dir)  \n",
    "\n",
    "for p in pieces:\n",
    "    bar_pos, events = pickle_load(os.path.join(data_dir, p))\n",
    "    events = events[ :bar_pos[-1] ]\n",
    "\n",
    "    polyph_raw = np.reshape(\n",
    "            compute_polyphonicity(events, n_bars=len(bar_pos)), (-1, 16)\n",
    "        )\n",
    "    rhythm_raw = np.reshape(\n",
    "            get_onsets_timing(events, n_bars=len(bar_pos)), (-1, 16)\n",
    "        )\n",
    "\n",
    "    polyph_cls = np.searchsorted(polyphonicity_bounds, np.mean(polyph_raw, axis=-1)).tolist()\n",
    "    rfreq_cls = np.searchsorted(rhym_intensity_bounds, np.mean(rhythm_raw, axis=-1)).tolist()\n",
    "\n",
    "    print('polyph_cls', polyph_cls)\n",
    "    print('rfreq_cls', rfreq_cls)\n",
    "\n",
    "    pickle.dump(polyph_cls, open(os.path.join(\n",
    "            polyph_out_dir, p), 'wb'\n",
    "        ))\n",
    "    pickle.dump(rfreq_cls, open(os.path.join(\n",
    "            rhythm_out_dir, p), 'wb'\n",
    "        ))\n",
    "\n",
    "    all_r_cls.extend(rfreq_cls)\n",
    "    all_p_cls.extend(polyph_cls)\n",
    "\n",
    "print ('[rhythm classes]', Counter(all_r_cls))\n",
    "print ('[polyph classes]', Counter(all_p_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def splitting_dataset(src, train_size=0.8, val_size=0.5):\n",
    "  data_list = [os.path.join(src, f) for f in os.listdir(src) if os.path.isfile(os.path.join(src, f))]\n",
    "\n",
    "  train_pieces = int(len(data_list)*train_size)\n",
    "  train_samples = data_list[: train_pieces]\n",
    "  val_samples = data_list[train_pieces: ]\n",
    "\n",
    "  val_pieces = int(len(val_samples)*val_size)\n",
    "  val_samples = val_samples[: val_pieces]\n",
    "  test_samples = val_samples[val_pieces: ]\n",
    "  return train_samples, val_samples, test_samples\n",
    "\n",
    "\n",
    "train_samples, val_samples, test_samples = splitting_dataset(src=r'D:\\UNI\\Thesis\\NeuralNotes\\data\\resource', train_size=0.8, val_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Training Samples\n",
      "[preparing data] now at #0\n"
     ]
    }
   ],
   "source": [
    "from dataloader import REMIFullSongTransformerDataset\n",
    "\n",
    "data_dir = r'D:\\UNI\\Thesis\\NeuralNotes\\data\\resource'\n",
    "vocab_path = r'D:\\UNI\\Thesis\\NeuralNotes\\agent\\pickles\\remi_vocab_v2.pkl'\n",
    "\n",
    "print('Dataset: Training Samples')\n",
    "dset = REMIFullSongTransformerDataset(\n",
    "  data_dir, vocab_path,\n",
    "  do_augment=True,\n",
    "  model_enc_seqlen=128,\n",
    "  model_dec_seqlen=1280,\n",
    "  model_max_bars=16,\n",
    "  pieces=train_samples,\n",
    "  pad_to_same=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'data_dir': './remi_dataset',\n",
       "  'train_split': './pickles/train_pieces.pkl',\n",
       "  'val_split': './pickles/val_pieces.pkl',\n",
       "  'test_split': './pickles/test_pieces.pkl',\n",
       "  'vocab_path': './pickles/remi_vocab_v2.pkl',\n",
       "  'max_bars': 16,\n",
       "  'enc_seqlen': 128,\n",
       "  'dec_seqlen': 1280,\n",
       "  'batch_size': 4},\n",
       " 'model': {'enc_n_layer': 6,\n",
       "  'enc_n_head': 4,\n",
       "  'enc_d_model': 256,\n",
       "  'enc_d_ff': 1024,\n",
       "  'dec_n_layer': 6,\n",
       "  'dec_n_head': 4,\n",
       "  'dec_d_model': 256,\n",
       "  'dec_d_ff': 1024,\n",
       "  'd_embed': 256,\n",
       "  'd_latent': 64,\n",
       "  'd_polyph_emb': 32,\n",
       "  'd_rfreq_emb': 32,\n",
       "  'cond_mode': 'in-attn',\n",
       "  'pretrained_params_path': None,\n",
       "  'pretrained_optim_path': None},\n",
       " 'training': {'device': 'cuda:0',\n",
       "  'ckpt_dir': './ckpt/mm_small.pt',\n",
       "  'trained_steps': 0,\n",
       "  'max_epochs': 1000,\n",
       "  'max_lr': 0.0001,\n",
       "  'min_lr': 5e-06,\n",
       "  'lr_warmup_steps': 200,\n",
       "  'lr_decay_steps': 150000,\n",
       "  'no_kl_steps': 10000,\n",
       "  'kl_cycle_steps': 5000,\n",
       "  'kl_max_beta': 1.0,\n",
       "  'free_bit_lambda': 0.25,\n",
       "  'constant_kl': False,\n",
       "  'ckpt_interval': 50,\n",
       "  'log_interval': 10,\n",
       "  'val_interval': 50},\n",
       " 'generate': {'temperature': 1.2,\n",
       "  'nucleus_p': 0.9,\n",
       "  'use_latent_sampling': False,\n",
       "  'latent_sampling_var': 0.0,\n",
       "  'max_bars': 16,\n",
       "  'dec_seqlen': 1280,\n",
       "  'max_input_dec_seqlen': 1024}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model_factory import Factory\n",
    "\n",
    "\n",
    "factory = Factory()\n",
    "model, config = factory.generate(dset=dset)\n",
    "\n",
    "config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musicgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
